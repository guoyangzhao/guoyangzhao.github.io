---
layout: archive
title: " "
permalink: /portfolio/
author_profile: true
---

<h2><span style="color: rgb(167, 35, 107);"><b>Research Projects:</b></span></h2>

<h3><span style="color: rgb(84, 33, 201);"><b>1. 24h Unmanned Patrol Vehicle System (2022.12-2024.08)</b></span></h3> 
· Mainly responsible for the construction of the perception system based on sensor fusion. <br>
· Panoramic semantic segmentation of unmanned vehicle surroundings using unsupervised method. <br>
· Use the improved YOLO model to identify pedestrians/facilities and use the NeRF model to reconstruct the surrounding environment. <br>
<img src='/images/car.png' width='163' height='200'>&nbsp;<img src='/images/vio.gif' width='331' height='200'>&nbsp;<img src='/images/seg.png' width='432' height='200'> <br>

<h3><span style="color: rgb(84, 33, 201);"><b>2. Soybean Seed Real-time Sorting System Based on Deep Learning (2019.05-2022.05, Project Leader)</b></span></h3>
·Construct a comprehensive data set by collecting images in six directions in the soybean seed space. <br>
·Build a lightweight model to realize accurate recognition of soybean at different defect scales; Improved and optimized the model for real-time recognition in edge devices. <br>
·Greatly improved the efficiency of soybean selection and breeding and provided a new method for the detection of ellipsoid-like surface defects. <br>
<img src='/images/soybean4.png' width='225' height='200'>&nbsp;<img src='/images/soybean2.png' width='273.67' height='200'>&nbsp;<img src='/images/soybean3.png' width='243' height='200'> <br>

<h3><span style="color: rgb(84, 33, 201);"><b>3. Research on field crop identification and navigation based on deep learning (2019.10-2022.01, main participant)</b></span></h3> 
·Used the deep learning detection model in the edge device to detect different types of weeds and seedlings of different leaf ages in the field. <br>
·The position of the weeds is transmitted to the end effector, and the pesticides are sprayed on the surface of the weeds, which greatly reduces the impact on the environment and the amount of pesticides used. <br>
·With team members, propose a row anchor selection classification method to help agricultural robots track crop rows. <br>
·Field images are processed by combining the row anchor selection method and lightweight model GhostNet, which achieves good results in both computational speed and accuracy. <br>
<img src='/images/field1.png' width='339.9' height='200'>&nbsp;<img src='/images/field3.png' width='228.4' height='200'>&nbsp;<img src='/images/field5.gif' width='345.97' height='200'> <br>


<h3><span style="color: rgb(84, 33, 201);"><b>4. XXXX</b></span></h3>
excerpt: "·Mainly responsible for the construction of the perception system based on sensor fusion. <br>
·Panoramic semantic segmentation of unmanned vehicle surroundings using unsupervised method. <br>
·Use the improved YOLO model to identify pedestrians/facilities and use the NeRF model to reconstruct the surrounding environment. <br>
<img src='/images/field4.png' width='330.3' height='200'> <br>



<h2><span style="color: rgb(167, 35, 107);"><b>Mini Projects:</b></span></h2>

------<br>
------<br>
------<br>
------<br>
------<br>
------<br>
------<br>
------<br>
------<br>
XXXXX<br>